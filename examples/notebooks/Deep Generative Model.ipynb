{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "import torch\n",
    "cuda = torch.cuda.is_available()\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import sys\n",
    "sys.path.append(\"../../semi-supervised\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Generative Model\n",
    "\n",
    "In this notebook we show how you can use the deep \"generative model for semi-supervised learning\" as presented in [[Kingma 2014]](https://arxiv.org/abs/1406.5298). The paper posits three different models, though we are just interested in two of these: the M2 model and the M1+M2 model.\n",
    "\n",
    "The M1 model is just a variational autoencoder, so we refer to the previous notebook for more information on this. The M2 model however is an extension to the VAE to include label information for a semi-supervised objective. The structure is shown below (left: inference model, right: generative model).\n",
    "\n",
    "<img src=\"../images/dgm.png\" width=\"400px\"/>\n",
    "\n",
    "The point of the generative model is to seperate the partially observed label information $y$ from the latent variable $z$ in order to learn a representation that seperates these two variables. We can use this model for semi-supervised learning as the inference model must also infer the label from the data $x$ along with the latent variable $z$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeepGenerativeModel(\n",
       "  (encoder): Encoder(\n",
       "    (hidden): ModuleList(\n",
       "      (0): Linear(in_features=794, out_features=256)\n",
       "      (1): Linear(in_features=256, out_features=128)\n",
       "    )\n",
       "    (sample): GaussianSample(\n",
       "      (mu): Linear(in_features=128, out_features=32)\n",
       "      (log_var): Linear(in_features=128, out_features=32)\n",
       "    )\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (hidden): ModuleList(\n",
       "      (0): Linear(in_features=42, out_features=128)\n",
       "      (1): Linear(in_features=128, out_features=256)\n",
       "    )\n",
       "    (reconstruction): Linear(in_features=256, out_features=784)\n",
       "    (output_activation): Sigmoid()\n",
       "  )\n",
       "  (classifier): Classifier(\n",
       "    (dense): Linear(in_features=784, out_features=256)\n",
       "    (logits): Linear(in_features=256, out_features=10)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from models import DeepGenerativeModel, StackedDeepGenerativeModel\n",
    "\n",
    "y_dim = 10\n",
    "z_dim = 32\n",
    "h_dim = [256, 128]\n",
    "\n",
    "model = DeepGenerativeModel([784, y_dim, z_dim, h_dim])\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear(in_features=794, out_features=256)\n",
      "Linear(in_features=42, out_features=128)\n"
     ]
    }
   ],
   "source": [
    "print(model.encoder.hidden[0])\n",
    "print(model.decoder.hidden[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how theres now a classifier associated with model. This classifier will just be a simple model that takes the size of the first layer encoder network. We also have a larger input space on both the encoder and decoder to make room for label information, in this case 10 labels.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "Recall the ELBO from the VAE formulation, we want to construct a similar ELBO when we include labelled data $y$. In the case that we have labels, the ELBO has a simple formulation that is similar to the one for the VAE. The difference here is that we must also have a prior over labels $p(y)$, which we choose to be uniform over the different classes.\n",
    "\n",
    "\\begin{align}\n",
    "\\log p(x, y) &= \\log \\int q(z|x, y) \\frac{p(x, y, z)}{q(z|xy)} \\ dz \\geq \\int q(z|x, y) \\log \\frac{p(x, y, z)}{q(z|xy)} \\ dz\\\\\n",
    "&= \\int q(z|x, y) [ \\log p(x|z,y) + \\log p(y) ] \\ dz + \\int q(z|x, y) \\log \\frac{p(z)}{q(z|xy)} \\ dz\\\\\n",
    "&= \\mathbb{E}_{q(z|x, y)} [ \\log p(x|z,y) + \\log p(y) ] - KL(p(z)||q(z|xy)) = - \\mathcal{L}(x, y)\n",
    "\\end{align}\n",
    "\n",
    "In the case when the labels are not observed, we can instead integrate over all of the labels to achieve the same effect.\n",
    "\n",
    "\\begin{align}\n",
    "\\log p(x) &= \\log \\sum_{y} \\int q(z,y|x) \\frac{p(x, y, z)}{q(z,y|x)} \\ dz \\geq \\sum_{y} q(y|x) \\int q(z|x, y) \\log \\frac{p(x, y, z)}{q(z,y|x)} \\ dz\\\\\n",
    "&= \\sum_{y} q(y|x) \\int q(z|x, y) \\log \\frac{p(x, y, z)}{q(z|x,y)} \\ dz - \\sum_{y} q(y|x) \\log q(y|x) \\int q(z|x, y) \\ dz\\\\\n",
    "&= \\sum_{y} q(y|x) (- \\mathcal{L}(x,y)) + \\mathcal{H}(q(y|x)) = - \\mathcal{U}(x)\n",
    "\\end{align}\n",
    "\n",
    "Notice how in both cases we need to compute the labelled bound, but in the unlabelled case we need to do it $n$ times where $n$ is the number of classes. In this model, we do not learn directly from the labelled class, as there is no cross entropy term between $y$ and our model output $q(y|x)$. We therefore add an auxiliary loss to arrive at the final loss objective.\n",
    "\n",
    "$$\\mathcal{J}^{\\alpha} = \\sum_{(x_l, y_l)}\\mathcal{L}(x_l, y_l) + \\alpha \\cdot \\mathbb{E}_{x_l, y_l}[- \\log q(y_l|x_l)] + \\sum_{(x_u)}\\mathcal{U}(x_u)$$\n",
    "\n",
    "Where $l, u$ denotes labelled and unlabelled data respectively and $\\alpha$ is a hyperparameter that denotes the reliance of labelled data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datautils import get_mnist\n",
    "\n",
    "# Only use 10 labelled examples per class\n",
    "# The rest of the data is unlabelled.\n",
    "labelled, unlabelled, validation = get_mnist(location=\"./\", batch_size=64, labels_per_class=10)\n",
    "alpha = 0.1 * len(unlabelled) / len(labelled)\n",
    "\n",
    "def binary_cross_entropy(r, x):\n",
    "    return -torch.sum(x * torch.log(r + 1e-8) + (1 - x) * torch.log(1 - r + 1e-8), dim=-1)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=3e-4, betas=(0.9, 0.999))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import cycle\n",
    "from inference import SVI, ImportanceWeightedSampler\n",
    "\n",
    "# You can use importance weighted samples [Burda, 2015] to get a better estimate\n",
    "# on the log-likelihood.\n",
    "sampler = ImportanceWeightedSampler(mc=1, iw=1)\n",
    "\n",
    "if cuda: model = model.cuda()\n",
    "elbo = SVI(model, likelihood=binary_cross_entropy, sampler=sampler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The library is conventially packed with the `SVI` method that does all of the work of calculating the lower bound for both labelled and unlabelled data depending on whether the label is given. It also manages to perform the enumeration of all the labels.\n",
    "\n",
    "Remember that the labels have to be in a *one-hot encoded* format in order to work with SVI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import Variable\n",
    "\n",
    "for epoch in range(10):\n",
    "    model.train()\n",
    "    total_loss, accuracy = (0, 0)\n",
    "    for (x, y), (u, _) in zip(cycle(labelled), unlabelled):\n",
    "        # Wrap in variables\n",
    "        x, y, u = Variable(x), Variable(y), Variable(u)\n",
    "\n",
    "        if cuda:\n",
    "            # They need to be on the same device and be synchronized.\n",
    "            x, y = x.cuda(device=0), y.cuda(device=0)\n",
    "            u = u.cuda(device=0)\n",
    "\n",
    "        L = -elbo(x, y)\n",
    "        U = -elbo(u)\n",
    "\n",
    "        # Add auxiliary classification loss q(y|x)\n",
    "        logits = model.classify(x)\n",
    "        \n",
    "        # Regular cross entropy\n",
    "        classication_loss = torch.sum(y * torch.log(logits + 1e-8), dim=1).mean()\n",
    "\n",
    "        J_alpha = L - alpha * classication_loss + U\n",
    "\n",
    "        J_alpha.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        total_loss += J_alpha.data[0]\n",
    "        accuracy += torch.mean((torch.max(logits, 1)[1].data == torch.max(y, 1)[1].data).float())\n",
    "        \n",
    "    if epoch % 1 == 0:\n",
    "        model.eval()\n",
    "        m = len(unlabelled)\n",
    "        print(\"Epoch: {}\".format(epoch))\n",
    "        print(\"[Train]\\t\\t J_a: {:.2f}, accuracy: {:.2f}\".format(total_loss / m, accuracy / m))\n",
    "\n",
    "        total_loss, accuracy = (0, 0)\n",
    "        for x, y in validation:\n",
    "            x, y = Variable(x), Variable(y)\n",
    "\n",
    "            if cuda:\n",
    "                x, y = x.cuda(device=0), y.cuda(device=0)\n",
    "\n",
    "            L = -elbo(x, y)\n",
    "            U = -elbo(x)\n",
    "\n",
    "            logits = model.classify(x)\n",
    "            classication_loss = -torch.sum(y * torch.log(logits + 1e-8), dim=1).mean()\n",
    "\n",
    "            J_alpha = L + alpha * classication_loss + U\n",
    "\n",
    "            total_loss += J_alpha.data[0]\n",
    "\n",
    "            _, pred_idx = torch.max(logits, 1)\n",
    "            _, lab_idx = torch.max(y, 1)\n",
    "            accuracy += torch.mean((torch.max(logits, 1)[1].data == torch.max(y, 1)[1].data).float())\n",
    "\n",
    "        m = len(validation)\n",
    "        print(\"[Validation]\\t J_a: {:.2f}, accuracy: {:.2f}\".format(total_loss / m, accuracy / m))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conditional generation\n",
    "\n",
    "When the model is done training you can generate samples conditionally given some normal distributed noise $z$ and a label $y$.\n",
    "\n",
    "*The model below has only trained for 10 iterations, so the perfomance is not representative*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import onehot\n",
    "model.eval()\n",
    "\n",
    "z = Variable(torch.randn(16, 32))\n",
    "\n",
    "# Generate a batch of 7s\n",
    "y = Variable(onehot(10)(7).repeat(16, 1))\n",
    "\n",
    "x_mu = model.sample(z, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABBIAAABXCAYAAAC5gmYKAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x12a7f2cf8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "f, axarr = plt.subplots(1, 16, figsize=(18, 12))\n",
    "\n",
    "samples = x_mu.data.view(-1, 28, 28).numpy()\n",
    "\n",
    "for i, ax in enumerate(axarr.flat):\n",
    "    ax.imshow(samples[i])\n",
    "    ax.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stacked Deep Generative Model\n",
    "\n",
    "The M1+M2 model also described in the same paper is an M1 model (VAE) with an M2 model stacked on top of it. That means that we train the a VAE end-to-end on the data given dataset, then we use the learned encoder as a feature extractor and feed the data transformed by the M1 encoder into the M2 model.\n",
    "\n",
    "We approach is somewhat similar to restricted boltzmann machines (RBMs) in the sense that we perform a layerwise training of the whole model by first training a level-1 feature extractor and stacking another model on top of this. The stacked model is therefore also more modular, but cannot be trained end-to-end, which is a downside."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import VariationalAutoencoder, StackedDeepGenerativeModel\n",
    "\n",
    "features = VariationalAutoencoder([784, z_dim, h_dim])\n",
    "model = StackedDeepGenerativeModel([784, y_dim, z_dim, h_dim], features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Typically, you would want to load a pretrained feature extractor VAE instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = torch.load(\"./your-pretrained-vae.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import Variable\n",
    "\n",
    "for epoch in range(10):\n",
    "    model.train()\n",
    "    total_loss, accuracy = (0, 0)\n",
    "    for (x, y), (u, _) in zip(cycle(labelled), unlabelled):\n",
    "        # Wrap in variables\n",
    "        x, y, u = Variable(x), Variable(y), Variable(u)\n",
    "\n",
    "        if cuda:\n",
    "            # They need to be on the same device and be synchronized.\n",
    "            x, y = x.cuda(device=0), y.cuda(device=0)\n",
    "            u = u.cuda(device=0)\n",
    "\n",
    "        L = -elbo(x, y)\n",
    "        U = -elbo(u)\n",
    "\n",
    "        # Add auxiliary classification loss q(y|x)\n",
    "        logits = model.classify(x)\n",
    "        \n",
    "        # Regular cross entropy\n",
    "        classication_loss = torch.sum(y * torch.log(logits + 1e-8), dim=1).mean()\n",
    "\n",
    "        J_alpha = L - alpha * classication_loss + U\n",
    "\n",
    "        J_alpha.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        total_loss += J_alpha.data[0]\n",
    "        accuracy += torch.mean((torch.max(logits, 1)[1].data == torch.max(y, 1)[1].data).float())\n",
    "        \n",
    "    if epoch % 1 == 0:\n",
    "        model.eval()\n",
    "        m = len(unlabelled)\n",
    "        print(\"Epoch: {}\".format(epoch))\n",
    "        print(\"[Train]\\t\\t J_a: {:.2f}, accuracy: {:.2f}\".format(total_loss / m, accuracy / m))\n",
    "\n",
    "        total_loss, accuracy = (0, 0)\n",
    "        for x, y in validation:\n",
    "            x, y = Variable(x), Variable(y)\n",
    "\n",
    "            if cuda:\n",
    "                x, y = x.cuda(device=0), y.cuda(device=0)\n",
    "\n",
    "            L = -elbo(x, y)\n",
    "            U = -elbo(x)\n",
    "\n",
    "            logits = model.classify(x)\n",
    "            classication_loss = -torch.sum(y * torch.log(logits + 1e-8), dim=1).mean()\n",
    "\n",
    "            J_alpha = L + alpha * classication_loss + U\n",
    "\n",
    "            total_loss += J_alpha.data[0]\n",
    "\n",
    "            _, pred_idx = torch.max(logits, 1)\n",
    "            _, lab_idx = torch.max(y, 1)\n",
    "            accuracy += torch.mean((torch.max(logits, 1)[1].data == torch.max(y, 1)[1].data).float())\n",
    "\n",
    "        m = len(validation)\n",
    "        print(\"[Validation]\\t J_a: {:.2f}, accuracy: {:.2f}\".format(total_loss / m, accuracy / m))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional tips\n",
    "\n",
    "You can change the built-in classifier with your own, for example if you want a CNN as a classifier you can do the following."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class ConvolutionalClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvolutionalClassifier, self).__init__()        \n",
    "        self.conv1 = nn.Conv2d(1, 64, kernel_size=3)\n",
    "        self.conv2 = nn.Conv2d(64, 32, kernel_size=3)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=4)\n",
    "\n",
    "        size = int((28 - 3) + 1)//4\n",
    "        size = int((size - 3) + 1)//4\n",
    "                \n",
    "        self.fc1 = nn.Linear(32*size**2, 50)\n",
    "        self.fc2 = nn.Linear(50, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        batch, *_ = x.size()\n",
    "        x = x.view(-1, 1, 28, 28)\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.pool(x)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.pool(x)\n",
    "        x = F.relu(x.view(batch, -1))\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        return F.softmax(x, dim=-1)\n",
    "\n",
    "classifier = ConvolutionalClassifier()\n",
    "model.classifier = classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeepGenerativeModel(\n",
       "  (encoder): Encoder(\n",
       "    (hidden): ModuleList(\n",
       "      (0): Linear(in_features=794, out_features=256)\n",
       "      (1): Linear(in_features=256, out_features=128)\n",
       "    )\n",
       "    (sample): GaussianSample(\n",
       "      (mu): Linear(in_features=128, out_features=32)\n",
       "      (log_var): Linear(in_features=128, out_features=32)\n",
       "    )\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (hidden): ModuleList(\n",
       "      (0): Linear(in_features=42, out_features=128)\n",
       "      (1): Linear(in_features=128, out_features=256)\n",
       "    )\n",
       "    (reconstruction): Linear(in_features=256, out_features=784)\n",
       "    (output_activation): Sigmoid()\n",
       "  )\n",
       "  (classifier): ConvolutionalClassifier(\n",
       "    (conv1): Conv2d (1, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (conv2): Conv2d (64, 32, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (pool): MaxPool2d(kernel_size=(4, 4), stride=(4, 4), dilation=(1, 1))\n",
       "    (fc1): Linear(in_features=32, out_features=50)\n",
       "    (fc2): Linear(in_features=50, out_features=10)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
